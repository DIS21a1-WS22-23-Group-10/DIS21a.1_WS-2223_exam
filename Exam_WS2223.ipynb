{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<img src=\"https://www.th-koeln.de/img/logo.svg\" style=\"float: right;\" width=\"200\">"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DIS21a 1 | Big Data | Exam WS 2022/23 | Group J (10)\n",
                "\n",
                "## Participants\n",
                "\n",
                "-   [Markus Hardtke](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2705)\n",
                "    -   Matriculation Number: 1234567\n",
                "-   [Furkan Erdogan](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2688)\n",
                "    -   Matriculation Number: 11136112\n",
                "-   [Jannik Loose](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2687)\n",
                "    -   Matriculation Number: 1234567\n",
                "-   [Gilles Romer](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2681)\n",
                "    -   Matriculation Number: 11139919\n",
                "\n",
                "---\n",
                "\n",
                "## Project Setup\n",
                "\n",
                "*This Setup was made for Windows users and will differ if you are using a different OS.    \n",
                "The recommended Python version used to run this notebook is 3.9.13*\n",
                "\n",
                "1. Virtual environment\n",
                "\n",
                "    *This step is required so you can install the required packages without affecting or filling up your global Python installation.*\n",
                "\n",
                "    ```bash\n",
                "    python3 -m venv .venv\n",
                "    source .venv/Scripts/activate\n",
                "    pip install -r requirements.txt\n",
                "    ```\n",
                "\n",
                "2. Git\n",
                "\n",
                "    *This step is required so unnecessary data from the Notebook is not pushed to the repository. This will automatically remove all metadata and execution counts from the Notebook as soon as you stage your file.*\n",
                "\n",
                "    1. Download JQ (flexible command-line JSON processor) from [here](https://github.com/stedolan/jq/releases/download/jq-1.6/jq-win64.exe)\n",
                "    2. Create the following Folder: `C:\\Program Files\\jq`\n",
                "    3. Add the following line to your PATH environment variable: `C:\\Program Files\\jq`\n",
                "    4. Rename the downloaded JQ file to `jq.exe` and move it to the previously created folder\n",
                "    5. Add the following lines to your .gitconfig file (usually found in C:\\Users\\YOUR_USERNAME\\.gitconfig)\n",
                "\n",
                "        ```bash\n",
                "        [core]\n",
                "            attributesfile = ~/.gitattributes_global\n",
                "        [filter \"nbstrip_meta\"]\n",
                "            clean = \"jq --indent 4 \\\n",
                "                    '(.cells[] | select(has(\\\"execution_count\\\")) | .execution_count) = null  \\\n",
                "                    | .metadata = {\\\"language_info\\\": {\\\"name\\\": \\\"python\\\", \\\"pygments_lexer\\\": \\\"ipython3\\\"}} \\\n",
                "                    | .cells[].metadata = {} \\\n",
                "                    '\"\n",
                "            smudge = cat\n",
                "            required = true\n",
                "        [filter \"nbstrip_full\"]\n",
                "            clean = \"jq --indent 4 \\\n",
                "                    '(.cells[] | select(has(\\\"outputs\\\")) | .outputs) = []  \\\n",
                "                    | (.cells[] | select(has(\\\"execution_count\\\")) | .execution_count) = null  \\\n",
                "                    | .metadata = {\\\"language_info\\\": {\\\"name\\\": \\\"python\\\", \\\"pygments_lexer\\\": \\\"ipython3\\\"}} \\\n",
                "                    | .cells[].metadata = {} \\\n",
                "                    '\"\n",
                "            smudge = cat\n",
                "            required = true\n",
                "        ```\n",
                "\n",
                "    6. Create a `.gitattributes_global` file at the same location as your `.gitconfig` file and add the following lines:\n",
                "\n",
                "        ```bash\n",
                "        *.ipynb filter=nbstrip_meta\n",
                "        ```\n",
                "\n",
                "3. Weights and Biases\n",
                "\n",
                "    *Weights and Biases is a tool that helps you track your experiments and visualize your results. It is also used to run hyperparameter sweeps.*  \n",
                "    \n",
                "    Make sure to create an account on [Weights and Biases](https://wandb.ai/site) and accept the invitation to the Team.  \n",
                "    Furthermore you will have to add your [API key](https://wandb.ai/settings#dangerzone) to the [scrts.py](./scrts.py) file under `wandb_api_key`.\n",
                "\n",
                "## Optional Setup\n",
                "\n",
                "1. Tensorflow GPU support  \n",
                "\n",
                "    *<span style=\"color:orange\">This step is optional and only required if you want to use a GPU for training.</span>*  \n",
                "   Follow this setup to activate tensorflow GPU support (Make sure to install the mentioned versions rather than the latest one!): [https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu)  \n",
                "   This tutorial will additionally help you to install CUDA and cuDNN: [https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/](https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/) \n",
                "\n",
                "---\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Objective\n",
                "\n",
                "The aim of this kernel is to predict <span style=\"color:orange\">partitions of images of different environments</span> from the dataset `environments` which are `{streets, sea, mountain, glacier, forest, buildings}`. We developed a classifier that distinguishes the images in the best possible way. The biggest challenge is to get the most accuracy with using our own image classification algorithm `categorical_classification` and trying out `ResNET` as an another image classification algorithm."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Environment Setup\n",
                "\n",
                "### Path's\n",
                "\n",
                "We're importing libraries `os` and `sys`. \n",
                "The os and sys modules provide numerous tools for dealing with file names, paths and directories. We're setting up the path to the root of our repository.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the necessary libraries\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Setting up the path to the root of the repository\n",
                "path = os.getcwd()\n",
                "notebookpath = os.path.join(path, 'Exam_WS2223.ipynb')\n",
                "\n",
                "datapath = os.path.join(path, 'data')\n",
                "data_testpath = os.path.join(datapath, 'seg_test')\n",
                "data_trainpath = os.path.join(datapath, 'seg_train')\n",
                "data_valpath = os.path.join(datapath, 'seg_pred')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Tensorflow version and GPU availability"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We're importing here important and necessary libraries. Then we're checking with the code the versions and gpu availability to set up the GPU if it was installed in the section above. This code then will tell if the GPU is available or not in case if one should have overlooked a step.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the libraries\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "import gc\n",
                "\n",
                "# Checking versions and gpu availability\n",
                "print(f\"Tensorflow version: {tf.__version__}\")\n",
                "print(f\"Keras Version: {tf.keras.__version__}\")\n",
                "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
                "\n",
                "# Setting up the GPU\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    try:\n",
                "        # Currently, memory growth needs to be the same across GPUs\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
                "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
                "    except RuntimeError as e:\n",
                "        # Memory growth must be set before GPUs have been initialized\n",
                "        print(e)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wandb"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we import more important libraries to remove unnecessary logs later.  \n",
                "**WandbMetricsLogger: Used for Experiment Tracking.  \n",
                "WandbModelCheckpoints: Used to log the model checkpoints to Weight and Biases Artifacts.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the libraries\n",
                "import wandb\n",
                "import scrts\n",
                "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
                "import logging\n",
                "import absl.logging\n",
                "import os\n",
                "\n",
                "# Removing all unnecessary logs\n",
                "# absl.logging.set_verbosity(absl.logging.ERROR)\n",
                "logger = logging.getLogger(\"wandb\")\n",
                "logger.setLevel(logging.ERROR)\n",
                "os.environ['WANDB_SILENT'] = 'true'\n",
                "os.environ['WANDB_CONSOLE'] = 'off'\n",
                "os.environ['WANDB_NOTEBOOK_NAME'] = notebookpath\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
                "\n",
                "if scrts.wandb_api_key is None:\n",
                "    print(\"Please enter your wandb API key in scrts.py\")\n",
                "else:\n",
                "    wandb.login(key=scrts.wandb_api_key)\n",
                "# wandb.init(project=\"Exam\", entity=\"dis21a1_ws22-21_gruppe10\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Helper functions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "# Plotting the loss and accuracy of the model\n",
                "def plot_loss_accuracy(history):\n",
                "    plt.figure(figsize=(10, 5))\n",
                "    plt.subplot(1, 2, 1)\n",
                "    plt.title(\"Loss\")\n",
                "    plt.plot(history.history[\"loss\"], label=\"Training loss\")\n",
                "    plt.plot(history.history[\"val_loss\"], label=\"Validation loss\")\n",
                "    plt.legend()\n",
                "    plt.subplot(1, 2, 2)\n",
                "    plt.title(\"Accuracy\")\n",
                "    plt.plot(history.history[\"accuracy\"], label=\"Training accuracy\")\n",
                "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation accuracy\")\n",
                "    plt.legend()\n",
                "    plt.show()\n",
                "\n",
                "# Showing random images with their labels from the dataset\n",
                "def show_random_images(images, labels, classes, num=5):\n",
                "    plt.figure(figsize=(10, 10))\n",
                "    for i in range(num):\n",
                "        plt.subplot(5, 5, i+1)\n",
                "        plt.xticks([])\n",
                "        plt.yticks([])\n",
                "        plt.grid(False)\n",
                "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
                "        plt.xlabel(classes[labels[i]])\n",
                "    plt.show()\n",
                "    \n",
                "# Data loading and preprocessing (... a bit)\n",
                "import random\n",
                "import numpy as np\n",
                "classes = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
                "\n",
                "def load_data(datapath, classes):\n",
                "    # Only load training and test data\n",
                "    for dataset in os.listdir(datapath):\n",
                "        if dataset == \"seg_train\" or dataset == \"seg_test\":\n",
                "            # Load the data\n",
                "            data = []\n",
                "            for folder in os.listdir(os.path.join(datapath, dataset)):\n",
                "                for image in os.listdir(os.path.join(datapath, dataset, folder)):\n",
                "                    # resize images to 150x150\n",
                "                    img = Image.open(os.path.join(datapath, dataset, folder, image))\n",
                "                    img = img.resize((150, 150))\n",
                "                    data.append([img, folder])\n",
                "            # Shuffle the data\n",
                "            random.shuffle(data)\n",
                "            # Split the images into data(the actual image) and labels\n",
                "            images = []\n",
                "            labels = []\n",
                "            for image in data:\n",
                "                images.append(image[0])\n",
                "                labels.append(image[1])\n",
                "            if dataset == \"seg_train\":\n",
                "                train_images = images\n",
                "                train_labels = labels\n",
                "            else:\n",
                "                test_images = images\n",
                "                test_labels = labels\n",
                "    return train_images, train_labels, test_images, test_labels\n",
                "\n",
                "# Data augmentation\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "def augment_data(datapath, classes, train_dir=data_trainpath, test_dir=data_testpath):\n",
                "    train_datagen = ImageDataGenerator(\n",
                "        rescale=1./255,\n",
                "        rotation_range=40,\n",
                "        width_shift_range=0.2,\n",
                "        height_shift_range=0.2,\n",
                "        shear_range=0.2,\n",
                "        zoom_range=0.2,\n",
                "        horizontal_flip=True,)\n",
                "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "    train_generator = train_datagen.flow_from_directory(\n",
                "        train_dir,\n",
                "        target_size=(150, 150),\n",
                "        batch_size=20,\n",
                "        class_mode='categorical')\n",
                "    test_generator = test_datagen.flow_from_directory(\n",
                "        test_dir,\n",
                "        target_size=(150, 150),\n",
                "        batch_size=20,\n",
                "        class_mode='categorical')\n",
                "    return train_generator, test_generator\n",
                "\n",
                "# Vectorizing the labels\n",
                "def label_vectorization(labels):\n",
                "    # Convert the labels to numbers\n",
                "    for i, label in enumerate(labels):\n",
                "        labels[i] = classes.index(label)\n",
                "    # One-hot encoding the labels\n",
                "    from tensorflow.keras.utils import to_categorical\n",
                "    labels = to_categorical(labels, num_classes=len(classes))\n",
                "    return labels\n",
                "\n",
                "# Normalizing the images\n",
                "def image_normalization(data):\n",
                "    # Convert the images to arrays\n",
                "    for i, image in enumerate(data):\n",
                "        data[i] = np.array(image, dtype=\"float32\")\n",
                "    # Normalize the images\n",
                "    data = np.array(data) / 255\n",
                "    return data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## What are we working with?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### What does the data look like?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This section is focused around training the data and to check if the training images have the same dimensions. For this purpose, a code was written that performs these steps for us and prints it out. If not, then it would print `The train/test image from the folder/image has different dimensions than the others`. Else, it will print `The training/testing data contains \"amount\" images with the dimensions \"data_train_imgsize_height\"x\"data_train_imgsize_width\".`\n",
                "\n",
                "This also applies to the validation part of this code.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "from PIL.ExifTags import TAGS\n",
                "\n",
                "# Show metadata of images and folders\n",
                "\n",
                "# Training data\n",
                "data_train_length = sum([len(files) for r, d, files in os.walk(data_trainpath)])\n",
                "# Check if all training images have the same dimensions\n",
                "for folder in os.listdir(data_trainpath):\n",
                "    for i, image in enumerate(os.listdir(os.path.join(data_trainpath, folder))):\n",
                "        if i == 0:\n",
                "            data_train_imgsize_heigt = Image.open(os.path.join(data_trainpath, folder, image)).height\n",
                "            data_train_imgsize_width = Image.open(os.path.join(data_trainpath, folder, image)).width\n",
                "        else:\n",
                "            if data_train_imgsize_heigt != Image.open(os.path.join(data_trainpath, folder, image)).height or data_train_imgsize_width != Image.open(os.path.join(data_trainpath, folder, image)).width:\n",
                "                print(f\"The train image {folder}/{image} has different dimensions than the others\")\n",
                "                break\n",
                "print(f\"The training data contains {sum([len(files) for r, d, files in os.walk(data_trainpath)])} images with the dimensions {data_train_imgsize_heigt}x{data_train_imgsize_width} pixels\")\n",
                "\n",
                "# Test data\n",
                "data_val_length = sum([len(files) for r, d, files in os.walk(data_valpath)])\n",
                "# Check if all test images have the same dimensions\n",
                "for folder in os.listdir(data_testpath):\n",
                "    for i, image in enumerate(os.listdir(os.path.join(data_testpath, folder))):\n",
                "        if i == 0:\n",
                "            data_test_imgsize_heigt = Image.open(os.path.join(data_testpath, folder, image)).height\n",
                "            data_test_imgsize_width = Image.open(os.path.join(data_testpath, folder, image)).width\n",
                "        else:\n",
                "            if data_test_imgsize_heigt != Image.open(os.path.join(data_testpath, folder, image)).height or data_test_imgsize_width != Image.open(os.path.join(data_testpath, folder, image)).width:\n",
                "                print(f\"The test image {folder}/{image} has different dimensions than the others\")\n",
                "                break\n",
                "print(f\"The test data contains {sum([len(files) for r, d, files in os.walk(data_testpath)])} images with the dimensions {data_test_imgsize_heigt}x{data_test_imgsize_width} pixels\")\n",
                "\n",
                "# Validation data\n",
                "data_val_length = sum([len(files) for r, d, files in os.walk(data_valpath)])\n",
                "# Check if all validation images have the same dimensions\n",
                "for i, image in enumerate(os.listdir(data_valpath)):\n",
                "    if i == 0:\n",
                "        data_val_imgsize_heigt = Image.open(os.path.join(data_valpath, image)).height\n",
                "        data_val_imgsize_width = Image.open(os.path.join(data_valpath, image)).width\n",
                "    else:\n",
                "        if data_val_imgsize_heigt != Image.open(os.path.join(data_valpath, image)) or data_val_imgsize_width != Image.open(os.path.join(data_valpath, image)):\n",
                "            print(f\"The validation image {image} has different dimensions than the others\")\n",
                "            break\n",
                "print(f\"The validation data contains {sum([len(files) for r, d, files in os.walk(data_valpath)])} images with the dimensions {data_val_imgsize_heigt}x{data_val_imgsize_width} pixels\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "General image size = 150x150"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loading and normalizing the data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we import the libraries `random` and `numpy` and try to load the dataset with the training data and testing data.\n",
                "\n",
                "We then load the images and shuffle the images, which are then split into data and labels with a defined function."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_images, train_labels, test_images, test_labels = load_data(datapath, classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_generator, test_generator = augment_data(datapath, classes)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Normalizing the data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Here we're vectorizing the labels and doing an [One-hot encoding the labels](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical). One-Hot Encoding is a popular technique for treating categorical variables. It simply creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature.\n",
                "\n",
                "We then normalized the images and converted them to arrays.\n",
                "\n",
                "The main purpose of this process is to bring the transformation so that all the features work on the same or similar level of scale."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_labels = label_vectorization(train_labels)\n",
                "test_labels = label_vectorization(test_labels)\n",
                "\n",
                "train_images = image_normalization(train_images)\n",
                "test_images = image_normalization(test_images)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Checking dataset structure again"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In this section we're checking the dimensions of the data again to make secure everything has worked so far. Then we import `matplotlib` and `seaborn` as libraries to show training and test data count for each class.\n",
                "\n",
                "Then we're visualizing the propotion each class which is it in the training and test data in a pie chart.\n",
                "We also show 5 random images in another "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Checking the dimensions of the data\n",
                "print(f\"The training data contains {len(train_images)} images with the dimensions {train_images[0].shape} pixels\")\n",
                "print(f\"The test data contains {len(test_images)} images with the dimensions {test_images[0].shape} pixels\")\n",
                "\n",
                "# Showing training and test data count for each class\n",
                "sns.set_style(\"darkgrid\")\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.title(\"Training and test data count for each class\")\n",
                "plt.xlabel(\"Class\")\n",
                "plt.ylabel(\"Count\")\n",
                "plt.bar(classes, [train_labels[:, i].sum() for i in range(len(classes))], label=\"Training data\")\n",
                "plt.bar(classes, [test_labels[:, i].sum() for i in range(len(classes))], label=\"Test data\")\n",
                "for i in range(len(classes)):\n",
                "    plt.text(x=classes[i], y=train_labels[:, i].sum(), s=train_labels[:, i].sum(), ha=\"center\")\n",
                "    plt.text(x=classes[i], y=test_labels[:, i].sum(), s=test_labels[:, i].sum(), ha=\"center\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Showing the proportion each class has in the training and test data in a pie chart\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.title(\"Training data proportions\")\n",
                "plt.pie([train_labels[:, i].sum() for i in range(len(classes))], labels=classes, autopct=\"%1.1f%%\")\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.title(\"Test data proportions\")\n",
                "plt.pie([test_labels[:, i].sum() for i in range(len(classes))], labels=classes, autopct=\"%1.1f%%\")\n",
                "plt.show()\n",
                "\n",
                "# Showing 5 random images from each class\n",
                "plt.figure(figsize=(5, 5))\n",
                "plt.suptitle(\"Image examples from each class\")\n",
                "for i in range(len(classes)):\n",
                "    plt.subplot(2, 3, i + 1)\n",
                "    plt.title(classes[i])\n",
                "    plt.axis(\"off\")\n",
                "    plt.imshow(train_images[np.random.choice(np.where(train_labels[:, i] == 1)[0])])\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Building the model\n",
                "\n",
                "Each Keras model is created using either the `Sequential` class, which is a linear stack of layers, or the Model functional class, which is more customizable. We're going to import Keras, obviously, but then also specifically the Sequential model type, `dense` layers, `dropout`, and `flatten` (to flatten the data before passing through the final, regular dense layer). Finally, we're using a convolutional neural network, so we're going to use `Conv2D` and `MaxPooling2D` for that.  Later in the code we train the model by defining a function with `batch_size`, `epochs` and `log_freq=10`.  At the end we fit the model and output `history`."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plain classification model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Importing the necessary libraries\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# model builder\n",
                "def build_model(layers=[32, 64, 128, 128], dropout=0.5, input_shape=(150, 150, 3)):\n",
                "    tf.keras.backend.clear_session()\n",
                "    gc.collect()\n",
                "    model = Sequential()\n",
                "\n",
                "    for i, layer in enumerate(layers):\n",
                "        if i == 0:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "        else:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\"))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "\n",
                "    model.add(Flatten())\n",
                "    model.add(Dropout(dropout))\n",
                "    model.add(Dense(512, activation=\"relu\"))\n",
                "    model.add(Dense(len(classes), activation=\"softmax\"))\n",
                "\n",
                "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
                "\n",
                "    return model\n",
                "\n",
                "# model training\n",
                "plain_model = build_model()\n",
                "plain_history = plain_model.fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), verbose=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# plotting the loss and accuracy of the model\n",
                "plot_loss_accuracy(plain_history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluating the model\n",
                "plain_test_loss, plain_test_accuracy = plain_model.evaluate(test_images, test_labels)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Resnet18 Model\n",
                "\n",
                "Residual neural networks or commonly known as `ResNets` are the type of neural network that applies identity mapping. What this means is that the input to some layer is passed directly or as a shortcut to some other layer."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from classification_models.keras import Classifiers\n",
                "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
                "def build_Resnet_model():\n",
                "    tf.keras.backend.clear_session()\n",
                "    gc.collect()\n",
                "    model = Sequential()\n",
                "\n",
                "    base = ResNet18(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
                "    model.add(base)\n",
                "    model.add(Flatten())\n",
                "    model.add(Dense(256, activation='relu'))\n",
                "    model.add(Dense(len(classes), activation='sigmoid'))\n",
                "\n",
                "    model.compile(\n",
                "        loss='categorical_crossentropy',\n",
                "        optimizer = \"rmsprop\",\n",
                "        metrics=['acc']\n",
                "        )\n",
                "\n",
                "    return model\n",
                "\n",
                "# Model training\n",
                "# resnet18_model = build_Resnet_model()\n",
                "# resnet18_history = build_Resnet_model().fit(train_images, train_labels, epochs=20, batch_size=128, validation_data=(test_images, test_labels), verbose=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plotting the loss and accuracy of the model\n",
                "# plot_loss_accuracy(resnet18_history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluating the model\n",
                "# resnet18_test_loss, resnet18_test_accuracy = resnet18_model.evaluate(test_images, test_labels)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Classification model with data augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# model builder\n",
                "def build_model(layers=[32, 64, 128, 128], dropout=0.5, input_shape=(150, 150, 3)):\n",
                "    tf.keras.backend.clear_session()\n",
                "    gc.collect()\n",
                "    model = Sequential()\n",
                "\n",
                "    for i, layer in enumerate(layers):\n",
                "        if i == 0:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "        else:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\"))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "\n",
                "    model.add(Flatten())\n",
                "    model.add(Dropout(dropout))\n",
                "    model.add(Dense(512, activation=\"relu\"))\n",
                "    model.add(Dense(len(classes), activation=\"softmax\"))\n",
                "\n",
                "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
                "\n",
                "    return model\n",
                "\n",
                "# model training\n",
                "# DA_model = build_model()\n",
                "# DA_history = build_model().fit(train_generator, epochs=20, batch_size=128, validation_data=test_generator, verbose=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plotting the loss and accuracy of the model\n",
                "# plot_loss_accuracy(DA_history)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Evaluating the model\n",
                "# DA_test_loss, DA_test_accuracy = DA_model.evaluate(test_images, test_labels)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Hyperparameter tuning on best model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vector of probabilities\n",
                "predictions = plain_model.predict(test_images)\n",
                "# We take the highest probability\n",
                "pred_labels = np.argmax(predictions, axis = 1)\n",
                "\n",
                "show_random_images(test_images, pred_labels, test_labels, classes)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
