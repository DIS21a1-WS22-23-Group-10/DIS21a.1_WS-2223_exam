{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# DIS21a 1 | Big Data | Exam WS 2022/23 | Group J (10)\n",
                "\n",
                "## Participants\n",
                "\n",
                "-   [Markus Hardtke](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2705)\n",
                "    -   Matriculation Number: 1234567\n",
                "-   [Furkan Erdogan](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2688)\n",
                "    -   Matriculation Number: 1234567\n",
                "-   [Jannik Loose](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2687)\n",
                "    -   Matriculation Number: 1234567\n",
                "-   [Gilles Romer](https://elearning.iws.th-koeln.de/moodle/user/profile.php?id=2681)\n",
                "    -   Matriculation Number: 11139919\n",
                "\n",
                "---\n",
                "\n",
                "## Project Setup\n",
                "\n",
                "*This Setup was made for Windows users and will differ if you are using a different OS.    \n",
                "The recommended Python version used to run this notebook is 3.9.13*\n",
                "\n",
                "1. Virtual environment\n",
                "\n",
                "    *This step is required so you can install the required packages without affecting or filling up your global Python installation.*\n",
                "\n",
                "    ```bash\n",
                "    python3 -m venv .venv\n",
                "    source .venv/Scripts/activate\n",
                "    pip install -r requirements.txt\n",
                "    ```\n",
                "\n",
                "2. Git\n",
                "\n",
                "    *This step is required so unnecessary data from the Notebook is not pushed to the repository. This will automatically remove all metadata and execution counts from the Notebook as soon as you stage your file.*\n",
                "\n",
                "    1. Download JQ (flexible command-line JSON processor) from [here](https://github.com/stedolan/jq/releases/download/jq-1.6/jq-win64.exe)\n",
                "    2. Create the following Folder: `C:\\Program Files\\jq`\n",
                "    3. Add the following line to your PATH environment variable: `C:\\Program Files\\jq`\n",
                "    4. Rename the downloaded JQ file to `jq.exe` and move it to the previously created folder\n",
                "    5. Add the following lines to your .gitconfig file (usually found in C:\\Users\\YOUR_USERNAME\\.gitconfig)\n",
                "\n",
                "        ```bash\n",
                "        [core]\n",
                "            attributesfile = ~/.gitattributes_global\n",
                "        [filter \"nbstrip_meta\"]\n",
                "            clean = \"jq --indent 4 \\\n",
                "                    '(.cells[] | select(has(\\\"execution_count\\\")) | .execution_count) = null  \\\n",
                "                    | .metadata = {\\\"language_info\\\": {\\\"name\\\": \\\"python\\\", \\\"pygments_lexer\\\": \\\"ipython3\\\"}} \\\n",
                "                    | .cells[].metadata = {} \\\n",
                "                    '\"\n",
                "            smudge = cat\n",
                "            required = true\n",
                "        [filter \"nbstrip_full\"]\n",
                "            clean = \"jq --indent 4 \\\n",
                "                    '(.cells[] | select(has(\\\"outputs\\\")) | .outputs) = []  \\\n",
                "                    | (.cells[] | select(has(\\\"execution_count\\\")) | .execution_count) = null  \\\n",
                "                    | .metadata = {\\\"language_info\\\": {\\\"name\\\": \\\"python\\\", \\\"pygments_lexer\\\": \\\"ipython3\\\"}} \\\n",
                "                    | .cells[].metadata = {} \\\n",
                "                    '\"\n",
                "            smudge = cat\n",
                "            required = true\n",
                "        ```\n",
                "\n",
                "    6. Create a `.gitattributes_global` file at the same location as your `.gitconfig` file and add the following lines:\n",
                "\n",
                "        ```bash\n",
                "        *.ipynb filter=nbstrip_meta\n",
                "        ```\n",
                "\n",
                "3. Weights and Biases\n",
                "\n",
                "    *Weights and Biases is a tool that helps you track your experiments and visualize your results. It is also used to run hyperparameter sweeps.*  \n",
                "    \n",
                "    Make sure to create an account on [Weights and Biases](https://wandb.ai/site) and accept the invitation to the Team.  \n",
                "    Furthermore you will have to add your [API key](https://wandb.ai/settings#dangerzone) to the [scrts.py](./scrts.py) file under `wandb_api_key`.\n",
                "\n",
                "## Optional Setup\n",
                "\n",
                "1. Tensorflow GPU support  \n",
                "\n",
                "    *<span style=\"color:orange\">This step is optional and only required if you want to use a GPU for training.</span>*  \n",
                "   Follow this setup to activate tensorflow GPU support (Make sure to install the mentioned versions rather than the latest one!): [https://www.tensorflow.org/install/gpu](https://www.tensorflow.org/install/gpu)  \n",
                "   This tutorial will additionally help you to install CUDA and cuDNN: [https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/](https://lifewithdata.com/2022/01/16/how-to-install-tensorflow-and-keras-with-gpu-support-on-windows/) \n",
                "\n",
                "---\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Environment Setup\n",
                "\n",
                "### Path's"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the necessary libraries\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Setting up the path to the root of the repository\n",
                "path = os.getcwd()\n",
                "notebookpath = os.path.join(path, 'Exam_WS2223.ipynb')\n",
                "\n",
                "datapath = os.path.join(path, 'data')\n",
                "data_testpath = os.path.join(datapath, 'seg_test')\n",
                "data_trainpath = os.path.join(datapath, 'seg_train')\n",
                "data_valpath = os.path.join(datapath, 'seg_pred')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Tensorflow version and GPU availability"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the libraries\n",
                "import tensorflow as tf\n",
                "from tensorflow import keras\n",
                "\n",
                "# Checking versions and gpu availability\n",
                "print(f\"Tensorflow version: {tf.__version__}\")\n",
                "print(f\"Keras Version: {tf.keras.__version__}\")\n",
                "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
                "\n",
                "# Setting up the GPU\n",
                "gpus = tf.config.list_physical_devices('GPU')\n",
                "if gpus:\n",
                "    try:\n",
                "        # Currently, memory growth needs to be the same across GPUs\n",
                "        for gpu in gpus:\n",
                "            tf.config.experimental.set_memory_growth(gpu, True)\n",
                "            logical_gpus = tf.config.list_logical_devices('GPU')\n",
                "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
                "    except RuntimeError as e:\n",
                "        # Memory growth must be set before GPUs have been initialized\n",
                "        print(e)\n"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Wandb"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the libraries\n",
                "import wandb\n",
                "import scrts\n",
                "from wandb.keras import WandbMetricsLogger, WandbModelCheckpoint\n",
                "import logging\n",
                "import absl.logging\n",
                "import os\n",
                "\n",
                "# Removing all unnecessary logs\n",
                "# absl.logging.set_verbosity(absl.logging.ERROR)\n",
                "logger = logging.getLogger(\"wandb\")\n",
                "logger.setLevel(logging.ERROR)\n",
                "os.environ['WANDB_SILENT'] = 'true'\n",
                "os.environ['WANDB_CONSOLE'] = 'off'\n",
                "os.environ['WANDB_NOTEBOOK_NAME'] = notebookpath\n",
                "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
                "\n",
                "if scrts.wandb_api_key is None:\n",
                "    print(\"Please enter your wandb API key in scrts.py\")\n",
                "else:\n",
                "    wandb.login(key=scrts.wandb_api_key)\n",
                "# wandb.init(project=\"Exam\", entity=\"dis21a1_ws22-21_gruppe10\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## What are we working with?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### What does the data look like?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from PIL import Image\n",
                "from PIL.ExifTags import TAGS\n",
                "\n",
                "# Show metadata of images and folders\n",
                "\n",
                "# Training data\n",
                "data_train_length = sum([len(files) for r, d, files in os.walk(data_trainpath)])\n",
                "# Check if all training images have the same dimensions\n",
                "for folder in os.listdir(data_trainpath):\n",
                "    for i, image in enumerate(os.listdir(os.path.join(data_trainpath, folder))):\n",
                "        if i == 0:\n",
                "            data_train_imgsize_heigt = Image.open(os.path.join(data_trainpath, folder, image)).height\n",
                "            data_train_imgsize_width = Image.open(os.path.join(data_trainpath, folder, image)).width\n",
                "        else:\n",
                "            if data_train_imgsize_heigt != Image.open(os.path.join(data_trainpath, folder, image)).height or data_train_imgsize_width != Image.open(os.path.join(data_trainpath, folder, image)).width:\n",
                "                print(f\"The train image {folder}/{image} has different dimensions than the others\")\n",
                "                break\n",
                "print(f\"The training data contains {sum([len(files) for r, d, files in os.walk(data_trainpath)])} images with the dimensions {data_train_imgsize_heigt}x{data_train_imgsize_width} pixels\")\n",
                "\n",
                "# Test data\n",
                "data_val_length = sum([len(files) for r, d, files in os.walk(data_valpath)])\n",
                "# Check if all test images have the same dimensions\n",
                "for folder in os.listdir(data_testpath):\n",
                "    for i, image in enumerate(os.listdir(os.path.join(data_testpath, folder))):\n",
                "        if i == 0:\n",
                "            data_test_imgsize_heigt = Image.open(os.path.join(data_testpath, folder, image)).height\n",
                "            data_test_imgsize_width = Image.open(os.path.join(data_testpath, folder, image)).width\n",
                "        else:\n",
                "            if data_test_imgsize_heigt != Image.open(os.path.join(data_testpath, folder, image)).height or data_test_imgsize_width != Image.open(os.path.join(data_testpath, folder, image)).width:\n",
                "                print(f\"The test image {folder}/{image} has different dimensions than the others\")\n",
                "                break\n",
                "print(f\"The test data contains {sum([len(files) for r, d, files in os.walk(data_testpath)])} images with the dimensions {data_test_imgsize_heigt}x{data_test_imgsize_width} pixels\")\n",
                "\n",
                "# Validation data\n",
                "data_val_length = sum([len(files) for r, d, files in os.walk(data_valpath)])\n",
                "# Check if all validation images have the same dimensions\n",
                "for i, image in enumerate(os.listdir(data_valpath)):\n",
                "    if i == 0:\n",
                "        data_val_imgsize_heigt = Image.open(os.path.join(data_valpath, image)).height\n",
                "        data_val_imgsize_width = Image.open(os.path.join(data_valpath, image)).width\n",
                "    else:\n",
                "        if data_val_imgsize_heigt != Image.open(os.path.join(data_valpath, image)) or data_val_imgsize_width != Image.open(os.path.join(data_valpath, image)):\n",
                "            print(f\"The validation image {image} has different dimensions than the others\")\n",
                "            break\n",
                "print(f\"The validation data contains {sum([len(files) for r, d, files in os.walk(data_valpath)])} images with the dimensions {data_val_imgsize_heigt}x{data_val_imgsize_width} pixels\")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "General image size = 150x150"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Loading and normalizing the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import random\n",
                "import numpy as np\n",
                "classes = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
                "\n",
                "def load_data(datapath, classes):\n",
                "    # Only load training and test data\n",
                "    for dataset in os.listdir(datapath):\n",
                "        if dataset == \"seg_train\" or dataset == \"seg_test\":\n",
                "            # Load the images\n",
                "            images = []\n",
                "            for folder in os.listdir(os.path.join(datapath, dataset)):\n",
                "                for image in os.listdir(os.path.join(datapath, dataset, folder)):\n",
                "                    # resize images to 150x150\n",
                "                    img = Image.open(os.path.join(datapath, dataset, folder, image))\n",
                "                    img = img.resize((150, 150))\n",
                "                    images.append([img, folder])\n",
                "            # Shuffle the images\n",
                "            random.shuffle(images)\n",
                "            # Split the images into data(the actual image) and labels\n",
                "            data = []\n",
                "            labels = []\n",
                "            for image in images:\n",
                "                data.append(image[0])\n",
                "                labels.append(image[1])\n",
                "            if dataset == \"seg_train\":\n",
                "                train_data = data\n",
                "                train_labels = labels\n",
                "            else:\n",
                "                test_data = data\n",
                "                test_labels = labels\n",
                "    return train_data, train_labels, test_data, test_labels\n",
                "\n",
                "train_data, train_labels, test_data, test_labels = load_data(datapath, classes)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "def augment_data(datapath, classes, train_dir=data_trainpath, test_dir=data_testpath):\n",
                "    train_datagen = ImageDataGenerator(\n",
                "        rescale=1./255,\n",
                "        rotation_range=40,\n",
                "        width_shift_range=0.2,\n",
                "        height_shift_range=0.2,\n",
                "        shear_range=0.2,\n",
                "        zoom_range=0.2,\n",
                "        horizontal_flip=True,)\n",
                "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
                "\n",
                "    train_generator = train_datagen.flow_from_directory(\n",
                "        train_dir,\n",
                "        target_size=(150, 150),\n",
                "        batch_size=20,\n",
                "        class_mode='categorical')\n",
                "    test_generator = test_datagen.flow_from_directory(\n",
                "        test_dir,\n",
                "        target_size=(150, 150),\n",
                "        batch_size=20,\n",
                "        class_mode='categorical')\n",
                "\n",
                "    return train_generator, test_generator\n",
                "\n",
                "train_generator, test_generator = augment_data(datapath, classes)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Normalizing the data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Vectorizing the labels\n",
                "def label_vectorization(labels):\n",
                "    # Convert the labels to numbers\n",
                "    for i, label in enumerate(labels):\n",
                "        labels[i] = classes.index(label)\n",
                "    # One-hot encoding the labels\n",
                "    from tensorflow.keras.utils import to_categorical\n",
                "    labels = to_categorical(labels, num_classes=len(classes))\n",
                "    return labels\n",
                "\n",
                "train_labels = label_vectorization(train_labels)\n",
                "test_labels = label_vectorization(test_labels)\n",
                "\n",
                "# Normalizing the images\n",
                "def image_normalization(data):\n",
                "    # Convert the images to arrays\n",
                "    for i, image in enumerate(data):\n",
                "        data[i] = np.array(image, dtype=\"float32\")\n",
                "    # Normalize the images\n",
                "    data = np.array(data) / 255\n",
                "    return data\n",
                "\n",
                "train_data = image_normalization(train_data)\n",
                "test_data = image_normalization(test_data)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Checking dataset structure again"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Checking the dimensions of the data\n",
                "print(f\"The training data contains {len(train_data)} images with the dimensions {train_data[0].shape} pixels\")\n",
                "print(f\"The test data contains {len(test_data)} images with the dimensions {test_data[0].shape} pixels\")\n",
                "\n",
                "# Showing training and test data count for each class\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "sns.set_style(\"darkgrid\")\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.title(\"Training and test data count for each class\")\n",
                "plt.xlabel(\"Class\")\n",
                "plt.ylabel(\"Count\")\n",
                "plt.bar(classes, [train_labels[:, i].sum() for i in range(len(classes))], label=\"Training data\")\n",
                "plt.bar(classes, [test_labels[:, i].sum() for i in range(len(classes))], label=\"Test data\")\n",
                "for i in range(len(classes)):\n",
                "    plt.text(x=classes[i], y=train_labels[:, i].sum(), s=train_labels[:, i].sum(), ha=\"center\")\n",
                "    plt.text(x=classes[i], y=test_labels[:, i].sum(), s=test_labels[:, i].sum(), ha=\"center\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                "\n",
                "# Showing the proportion each class has in the training and test data in a pie chart\n",
                "plt.figure(figsize=(10, 5))\n",
                "plt.subplot(1, 2, 1)\n",
                "plt.title(\"Training data proportions\")\n",
                "plt.pie([train_labels[:, i].sum() for i in range(len(classes))], labels=classes, autopct=\"%1.1f%%\")\n",
                "plt.subplot(1, 2, 2)\n",
                "plt.title(\"Test data proportions\")\n",
                "plt.pie([test_labels[:, i].sum() for i in range(len(classes))], labels=classes, autopct=\"%1.1f%%\")\n",
                "plt.show()\n",
                "\n",
                "# Showing 5 random images from each class\n",
                "plt.figure(figsize=(15, 10))\n",
                "plt.suptitle(\"Image examples from each class\")\n",
                "for i in range(len(classes)):\n",
                "    plt.subplot(2, 3, i + 1)\n",
                "    plt.title(classes[i])\n",
                "    plt.axis(\"off\")\n",
                "    plt.imshow(train_data[np.random.choice(np.where(train_labels[:, i] == 1)[0])])\n",
                "plt.show()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "## Building the model"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Plain classification model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the necessary libraries\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# model builder\n",
                "def build_model(layers=[32, 64, 128, 128], dropout=0.5, input_shape=(150, 150, 3)):\n",
                "    model = Sequential()\n",
                "\n",
                "    for i, layer in enumerate(layers):\n",
                "        if i == 0:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "        else:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\"))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "\n",
                "    model.add(Flatten())\n",
                "    model.add(Dropout(dropout))\n",
                "    model.add(Dense(512, activation=\"relu\"))\n",
                "    model.add(Dense(len(classes), activation=\"softmax\"))\n",
                "\n",
                "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
                "\n",
                "    return model\n",
                "\n",
                "# model training\n",
                "history = build_model().fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Resnet18 Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from classification_models.keras import Classifiers\n",
                "ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
                "def build_Resnet_model():\n",
                "    model = Sequential()\n",
                "\n",
                "    base = ResNet18(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
                "    model.add(base)\n",
                "    model.add(Flatten())\n",
                "    model.add(Dense(256, activation='relu'))\n",
                "    model.add(Dense(len(classes), activation='sigmoid'))\n",
                "\n",
                "    model.compile(\n",
                "        loss='categorical_crossentropy',\n",
                "        optimizer = \"rmsprop\",\n",
                "        metrics=['acc']\n",
                "        )\n",
                "\n",
                "    return model\n",
                "history = build_Resnet_model().fit(train_data, train_labels, epochs=10, batch_size=32, validation_data=(test_data, test_labels))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "### Classification model with data augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Importing the necessary libraries\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
                "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
                "\n",
                "# model builder\n",
                "def build_model(layers=[32, 64, 128, 128], dropout=0.5, input_shape=(150, 150, 3)):\n",
                "    model = Sequential()\n",
                "\n",
                "    for i, layer in enumerate(layers):\n",
                "        if i == 0:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\", input_shape=input_shape))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "        else:\n",
                "            model.add(Conv2D(layer, (3, 3), activation=\"relu\"))\n",
                "            model.add(MaxPooling2D((2, 2)))\n",
                "\n",
                "    model.add(Flatten())\n",
                "    model.add(Dropout(dropout))\n",
                "    model.add(Dense(512, activation=\"relu\"))\n",
                "    model.add(Dense(len(classes), activation=\"softmax\"))\n",
                "\n",
                "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
                "\n",
                "    return model\n",
                "\n",
                "# model training\n",
                "history = build_model().fit(train_generator, epochs=10, batch_size=32, validation_data=test_generator)"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python",
            "pygments_lexer": "ipython3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
